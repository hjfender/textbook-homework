{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Machine Learning, the goal is to achieve models that *generalize* well to unseen data. *Overfitting* is the central obstacle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating a model always boild down to splitting the available data into three sets:\n",
    "- **training** (train the model on this)\n",
    "- **validation** (evaluate the model on this)\n",
    "- **test** (final check for the model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want 3 datasets instead of 2 because we don't want to \"overfit\" our *tuning* process. We can end up choosing *hyperparameter* values that are specific to good performance on the validation set, but not in general.\n",
    "\n",
    "Central to this phenomenon is the notion of *information leaks*. Every time you tune a hyperparameter of your model based on the model's performance on the validation set, some information about the validation data \"leaks\" into the model.\n",
    "\n",
    "By the time the test data set is used it shouldn't have impacted the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several ways to split data into training, validation, and test sets..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "data = random.choices(range(100000), k=50000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Hold-Out Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set apart some fraction of your data as your test set. Train on the remaining data and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_validation_samples = 10000\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_data = data[:num_validation_samples]\n",
    "data = data[num_validation_samples]\n",
    "\n",
    "training_data = data[:]\n",
    "\n",
    "model = get_model()\n",
    "model.train(training_data)\n",
    "validation_score = model.evaluate(validation_data)\n",
    "\n",
    "# At this point you can tune your model,\n",
    "# retrain it, evaluate it, tune it again...\n",
    "\n",
    "model = get_model()\n",
    "model.train(np.concatenate(\n",
    "    [training_data, validation_data]\n",
    "))\n",
    "\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the simplest evaluation protocol and it suffers from one flaw: if little data is available, then your validation and test sets may contain too few samples to be statistically representative of the data at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into *K* partitions of equal size. For each partition `i`, train a model on the remaining *K*-*1* partitions and evaluate it on partition `i`. The final score is then the averages of the *K* scores obtained. Helpful when the performance of the model shows significant variance based on your train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 4\n",
    "num_validation_samples = len(data) // k\n",
    "\n",
    "np.random.shuffle(data)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    validation_data = data[num_validation_samples * fold: num_validation_samples * (fold + 1)]\n",
    "    training_data = data[:num_validation_samples * fold] + data[num_validation_samples * (fold + 1):]\n",
    "\n",
    "    model = get_model()\n",
    "    model.train(training_data)\n",
    "    validation_score = model.evaluate(validation_data)\n",
    "    validation_scores.append(validation_score)\n",
    "\n",
    "validation_score = np.average(validation_scores)\n",
    "\n",
    "model = get_model()\n",
    "model.train(data)\n",
    "test_score = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterated K-Fold Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This technique is for situations in which you have relatively little data available and you need to evaluate your model as precisely as possible. (Helpful in Kaggle competitions)\n",
    "\n",
    "Consists of applying *K*-fold validation multiple times, shuffling the data every time befroe splitting it *K* ways. The final score is the average of the scores obtained at each run of *K*-fold validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to keep in mind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Data representativeness**: want both the training set and test set to be representative of the data at hand. Try random shuffling before sampling to ensure this.\n",
    "- **The arrow of time**: If data includes a time component, don't randomly shuffle the data before splitting it because otherwise you will cause a *temporal leak* and the model will be trained on future data it should not have access to.\n",
    "- **Redundancy in your data**: If some data points in yout data appear twice or more, then shuffling the data and splitting it into training and validation sets will result in redundancy between the two sets. So the training process will have access to data that it is being evaluated on which is taints model effectiveness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textbook-homework-S1kjZFOz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

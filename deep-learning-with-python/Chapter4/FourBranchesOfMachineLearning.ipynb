{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learn to map input data to known targets (*annotations*) given a set of examples (pre-annotated).\n",
    "\n",
    "Specialized variants of supervised learning:\n",
    "- **Sequence generation**: Given a picture, predict a caption describing it. Sequence generation can sometimes be reformulated as a series of classification problems (such as repeatedly predicting a word or token in a sequence).\n",
    "- **Syntax tree prediction**: Given a setence, predict its decomposition into a syntax tree.\n",
    "- **Object detection**: Given a picture, draw a bounding box around certain objects inside the picture. This can also be expressed as a classification problem (given many candidate bounding boxes, classify the contents of each one) or as a joint classification and regression problem, where the bounding-box coordinates are predicted via vector regression.\n",
    "- **Image segmentation**: Given a picture, draw a pixel-level mask on a specific object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consists of finding interesting transformations of the input data without the help of any targets, for the purposes of data visualization, data compression, or data denoising, or to better understand the correlation present in the data at hand.\n",
    "\n",
    "Well-known categories of unsupervised learning:\n",
    "- **Dimensionality reduction**\n",
    "- **Clustering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Specific instance of supervised learning (but different enough it gets its own category). It is supervised learning without the human-annotations (no human inputs in the learning process). Labels still exist but are generated from the input data (usually from some heuristic algorithm).\n",
    "\n",
    "**Autoencoders** are a well-known instance of self-supervised learning, where the generated targets are the input, unmodified.\n",
    "\n",
    "**Temporally Supervised Learning**: Supervision comes from future data (think of autocomplete on a phone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An *agent* receives information about its environment and learns to choose actions that will maximize some reward. (Useful to teach computers how play games)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

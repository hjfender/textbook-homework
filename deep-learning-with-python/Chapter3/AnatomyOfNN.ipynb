{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At their core Neural Networks consist of:\n",
    "- *Layers*, which are combined into a *network* (or *model*)\n",
    "- The *input data* and corresponding *targets*\n",
    "- The *loss function*, which defines the feedback signal used for learning\n",
    "- The *optimizer*, which determines how learning proceeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Neural Network Training Process Diagram](NN-Training-Process.svg \"Neural Network Training Process Diagram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Different layers are appropriate for different tensor formats and different types of data processing.\n",
    "- Simple vector data, stored in 2D tensors, is often processed by *densely connected*/*fully connected*/*dense* layers\n",
    "- Sequence data, stored in 3D tensors, is typically processed by *recurrent* layers such as a `LTSM` layer\n",
    "- Image data, stored in 4D tensors, is usually processed by 2D convolution layers like `Conv2D`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, input_shape=(784,)))\n",
    "model.add(layers.Dense(32)) # this layer infers its input shape from the output of the previous layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models: Networks of Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "A deep-learning model is a **directed, acyclic graph** of layers. Most commonly this is a linear stack of layers, but there are other network topologies\n",
    "- Two-branch networks\n",
    "- Multihead networks\n",
    "- Inception blocks\n",
    "\n",
    "Network topology defines a *hypothesis space* (constraining your *space of possibilities* to a specific series of tensor operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### Loss Functions and Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Loss Function*/*Objective Function* : The quantity that will be minimized during training. It represents a measure of success for the task at hand.\n",
    "- *Optimizer* : Determines how the network will be updated based on the loss function. It implements a specific variant of stochastic gradient descent (SGD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For multiloss networks, all losses are averaged into a single quantity so we can still find compute gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing the right objective function is *extremely* important. Choose a loss function that embodies the *right* constraints for your problem, so that minimization correlates with model success."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
